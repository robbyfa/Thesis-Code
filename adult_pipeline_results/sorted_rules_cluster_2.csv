antecedents,consequents,antecedent support,consequent support,support,confidence,lift,leverage,conviction,zhangs_metric,total_items,coverage
"frozenset({'marital-status_Married-civ-spouse', 'race_Asian-Pac-Islander'})",frozenset({'native_country_aggregated_Other'}),0.04516129032258064,0.08387096774193549,0.03870967741935484,0.8571428571428572,10.219780219780219,0.0349219562955255,6.412903225806454,0.9448198198198199,3,0.04516129032258064
"frozenset({'workclass_Private', 'race_Asian-Pac-Islander'})",frozenset({'native_country_aggregated_Other'}),0.03870967741935484,0.08387096774193549,0.03225806451612903,0.8333333333333333,9.935897435897434,0.029011446409989594,5.496774193548385,0.9355704697986578,3,0.03870967741935484
frozenset({'race_Asian-Pac-Islander'}),"frozenset({'marital-status_Married-civ-spouse', 'native_country_aggregated_Other'})",0.05806451612903226,0.07741935483870968,0.03870967741935484,0.6666666666666666,8.61111111111111,0.03421436004162331,2.767741935483871,0.9383561643835617,3,0.05806451612903226
"frozenset({'race_Asian-Pac-Islander', 'sex_Male'})",frozenset({'native_country_aggregated_Other'}),0.04516129032258064,0.08387096774193549,0.03225806451612903,0.7142857142857143,8.516483516483516,0.028470343392299688,3.206451612903226,0.9243243243243243,3,0.04516129032258064
"frozenset({'age_education_interaction_(494.0, 1350.0]', 'race_Asian-Pac-Islander'})",frozenset({'native_country_aggregated_Other'}),0.04516129032258064,0.08387096774193549,0.03225806451612903,0.7142857142857143,8.516483516483516,0.028470343392299688,3.206451612903226,0.9243243243243243,3,0.04516129032258064
frozenset({'race_Asian-Pac-Islander'}),frozenset({'native_country_aggregated_Other'}),0.05806451612903226,0.08387096774193549,0.03870967741935484,0.6666666666666666,7.948717948717948,0.033839750260145685,2.7483870967741932,0.9280821917808221,2,0.05806451612903226
"frozenset({'age_education_interaction_(494.0, 1350.0]', 'marital-status_Never-married'})",frozenset({'relationship_Not-in-family'}),0.03225806451612903,0.12903225806451613,0.03225806451612903,1.0,7.75,0.02809573361082206,inf,0.9,3,0.03225806451612903
"frozenset({'sex_Male', 'marital-status_Never-married'})",frozenset({'relationship_Not-in-family'}),0.03870967741935484,0.12903225806451613,0.03225806451612903,0.8333333333333333,6.458333333333333,0.027263267429760665,5.225806451612901,0.8791946308724832,3,0.03870967741935484
frozenset({'occupation_aggregated_Craft-repair'}),"frozenset({'education_HS-grad', 'sex_Male'})",0.05161290322580645,0.11612903225806452,0.03870967741935484,0.75,6.458333333333333,0.0327159209157128,3.535483870967742,0.891156462585034,3,0.05161290322580645
"frozenset({'native_country_aggregated_United-States', 'marital-status_Never-married'})",frozenset({'relationship_Not-in-family'}),0.05806451612903226,0.12903225806451613,0.04516129032258064,0.7777777777777777,6.027777777777777,0.03766909469302809,3.9193548387096757,0.8855185909980431,3,0.05806451612903226
"frozenset({'race_White', 'marital-status_Never-married'})",frozenset({'relationship_Not-in-family'}),0.05161290322580645,0.12903225806451613,0.03870967741935484,0.75,5.8125,0.03204994797086368,3.4838709677419355,0.873015873015873,3,0.05161290322580645
frozenset({'occupation_aggregated_Craft-repair'}),"frozenset({'education_HS-grad', 'native_country_aggregated_United-States'})",0.05161290322580645,0.12903225806451613,0.03870967741935484,0.75,5.8125,0.03204994797086368,3.4838709677419355,0.873015873015873,3,0.05161290322580645
"frozenset({'occupation_aggregated_Craft-repair', 'sex_Male'})",frozenset({'education_HS-grad'}),0.04516129032258064,0.14838709677419354,0.03870967741935484,0.8571428571428572,5.776397515527951,0.03200832466181062,5.9612903225806475,0.8659909909909911,3,0.04516129032258064
frozenset({'marital-status_Never-married'}),frozenset({'relationship_Not-in-family'}),0.07096774193548387,0.12903225806451613,0.05161290322580645,0.7272727272727273,5.636363636363637,0.04245577523413111,3.1935483870967745,0.8854166666666666,2,0.07096774193548387
"frozenset({'occupation_aggregated_Craft-repair', 'marital-status_Married-civ-spouse'})",frozenset({'education_HS-grad'}),0.03870967741935484,0.14838709677419354,0.03225806451612903,0.8333333333333333,5.615942028985507,0.02651404786680541,5.109677419354836,0.8550335570469799,3,0.03870967741935484
frozenset({'occupation_aggregated_Craft-repair'}),"frozenset({'education_HS-grad', 'race_White'})",0.05161290322580645,0.13548387096774195,0.03870967741935484,0.75,5.535714285714286,0.031716961498439125,3.458064516129032,0.8639455782312925,3,0.05161290322580645
frozenset({'occupation_aggregated_Craft-repair'}),frozenset({'education_HS-grad'}),0.05161290322580645,0.14838709677419354,0.03870967741935484,0.75,5.054347826086957,0.031050988553590012,3.4064516129032256,0.8458049886621316,2,0.05161290322580645
"frozenset({'occupation_aggregated_Craft-repair', 'native_country_aggregated_United-States'})",frozenset({'education_HS-grad'}),0.05161290322580645,0.14838709677419354,0.03870967741935484,0.75,5.054347826086957,0.031050988553590012,3.4064516129032256,0.8458049886621316,3,0.05161290322580645
"frozenset({'occupation_aggregated_Craft-repair', 'race_White'})",frozenset({'education_HS-grad'}),0.05161290322580645,0.14838709677419354,0.03870967741935484,0.75,5.054347826086957,0.031050988553590012,3.4064516129032256,0.8458049886621316,3,0.05161290322580645
"frozenset({'hours_per_week_binned_41-50', 'age_education_interaction_(369.0, 494.0]'})",frozenset({'education_HS-grad'}),0.04516129032258064,0.14838709677419354,0.03225806451612903,0.7142857142857143,4.813664596273292,0.02555671175858481,2.9806451612903224,0.8297297297297298,3,0.04516129032258064
"frozenset({'age_education_interaction_(261.0, 369.0]', 'sex_Male'})",frozenset({'education_HS-grad'}),0.06451612903225806,0.14838709677419354,0.04516129032258064,0.7,4.717391304347826,0.035587929240374606,2.838709677419354,0.8423645320197044,3,0.06451612903225806
"frozenset({'workclass_Private', 'occupation_aggregated_Sales'})","frozenset({'age_education_interaction_(369.0, 494.0]'})",0.06451612903225806,0.16129032258064516,0.04516129032258064,0.7,4.34,0.034755463059313214,2.7956989247311825,0.8226600985221675,3,0.06451612903225806
"frozenset({'education_HS-grad', 'age_education_interaction_(494.0, 1350.0]'})",frozenset({'hours_per_week_binned_41-50'}),0.03225806451612903,0.2967741935483871,0.03225806451612903,1.0,3.3695652173913047,0.022684703433922995,inf,0.7266666666666667,3,0.03225806451612903
"frozenset({'occupation_aggregated_Prof-specialty', 'race_Asian-Pac-Islander'})",frozenset({'education_Prof-school'}),0.03225806451612903,0.2967741935483871,0.03225806451612903,1.0,3.3695652173913047,0.022684703433922995,inf,0.7266666666666667,3,0.03225806451612903
