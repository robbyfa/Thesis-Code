antecedents,consequents,antecedent support,consequent support,support,confidence,lift,leverage,conviction,zhangs_metric,total_items,coverage
frozenset({'education_Some-college'}),"frozenset({'education-num_(9.0, 10.0]'})",0.06837606837606838,0.06837606837606838,0.06837606837606838,1.0,14.624999999999998,0.0637007816494996,inf,1.0,2,0.06837606837606838
"frozenset({'education-num_(9.0, 10.0]'})",frozenset({'education_Some-college'}),0.06837606837606838,0.06837606837606838,0.06837606837606838,1.0,14.624999999999998,0.0637007816494996,inf,1.0,2,0.06837606837606838
"frozenset({'education_Some-college', 'native_country_aggregated_United-States'})","frozenset({'education-num_(9.0, 10.0]'})",0.06837606837606838,0.06837606837606838,0.06837606837606838,1.0,14.624999999999998,0.0637007816494996,inf,1.0,3,0.06837606837606838
"frozenset({'education-num_(9.0, 10.0]', 'native_country_aggregated_United-States'})",frozenset({'education_Some-college'}),0.06837606837606838,0.06837606837606838,0.06837606837606838,1.0,14.624999999999998,0.0637007816494996,inf,1.0,3,0.06837606837606838
frozenset({'education_Some-college'}),"frozenset({'education-num_(9.0, 10.0]', 'native_country_aggregated_United-States'})",0.06837606837606838,0.06837606837606838,0.06837606837606838,1.0,14.624999999999998,0.0637007816494996,inf,1.0,3,0.06837606837606838
"frozenset({'education-num_(9.0, 10.0]'})","frozenset({'education_Some-college', 'native_country_aggregated_United-States'})",0.06837606837606838,0.06837606837606838,0.06837606837606838,1.0,14.624999999999998,0.0637007816494996,inf,1.0,3,0.06837606837606838
"frozenset({'education_Some-college', 'Cluster_(0.0, 2.0]'})","frozenset({'education-num_(9.0, 10.0]'})",0.06837606837606838,0.06837606837606838,0.06837606837606838,1.0,14.624999999999998,0.0637007816494996,inf,1.0,3,0.06837606837606838
"frozenset({'education-num_(9.0, 10.0]', 'Cluster_(0.0, 2.0]'})",frozenset({'education_Some-college'}),0.06837606837606838,0.06837606837606838,0.06837606837606838,1.0,14.624999999999998,0.0637007816494996,inf,1.0,3,0.06837606837606838
frozenset({'education_Some-college'}),"frozenset({'education-num_(9.0, 10.0]', 'Cluster_(0.0, 2.0]'})",0.06837606837606838,0.06837606837606838,0.06837606837606838,1.0,14.624999999999998,0.0637007816494996,inf,1.0,3,0.06837606837606838
"frozenset({'education-num_(9.0, 10.0]'})","frozenset({'education_Some-college', 'Cluster_(0.0, 2.0]'})",0.06837606837606838,0.06837606837606838,0.06837606837606838,1.0,14.624999999999998,0.0637007816494996,inf,1.0,3,0.06837606837606838
"frozenset({'workclass_Private', 'education_Some-college'})","frozenset({'education-num_(9.0, 10.0]'})",0.042735042735042736,0.06837606837606838,0.042735042735042736,1.0,14.624999999999998,0.039812988530937246,inf,0.9732142857142856,3,0.042735042735042736
"frozenset({'workclass_Private', 'education-num_(9.0, 10.0]'})",frozenset({'education_Some-college'}),0.042735042735042736,0.06837606837606838,0.042735042735042736,1.0,14.624999999999998,0.039812988530937246,inf,0.9732142857142856,3,0.042735042735042736
"frozenset({'marital-status_Married-civ-spouse', 'education_Some-college'})","frozenset({'education-num_(9.0, 10.0]'})",0.042735042735042736,0.06837606837606838,0.042735042735042736,1.0,14.624999999999998,0.039812988530937246,inf,0.9732142857142856,3,0.042735042735042736
"frozenset({'marital-status_Married-civ-spouse', 'education-num_(9.0, 10.0]'})",frozenset({'education_Some-college'}),0.042735042735042736,0.06837606837606838,0.042735042735042736,1.0,14.624999999999998,0.039812988530937246,inf,0.9732142857142856,3,0.042735042735042736
"frozenset({'education_Some-college', 'sex_Male'})","frozenset({'education-num_(9.0, 10.0]'})",0.042735042735042736,0.06837606837606838,0.042735042735042736,1.0,14.624999999999998,0.039812988530937246,inf,0.9732142857142856,3,0.042735042735042736
"frozenset({'education-num_(9.0, 10.0]', 'sex_Male'})",frozenset({'education_Some-college'}),0.042735042735042736,0.06837606837606838,0.042735042735042736,1.0,14.624999999999998,0.039812988530937246,inf,0.9732142857142856,3,0.042735042735042736
"frozenset({'race_White', 'education_Some-college'})","frozenset({'education-num_(9.0, 10.0]'})",0.042735042735042736,0.06837606837606838,0.042735042735042736,1.0,14.624999999999998,0.039812988530937246,inf,0.9732142857142856,3,0.042735042735042736
"frozenset({'race_White', 'education-num_(9.0, 10.0]'})",frozenset({'education_Some-college'}),0.042735042735042736,0.06837606837606838,0.042735042735042736,1.0,14.624999999999998,0.039812988530937246,inf,0.9732142857142856,3,0.042735042735042736
"frozenset({'education_HS-grad', 'age_(28.0, 37.0]'})","frozenset({'age_education_interaction_(261.0, 369.0]'})",0.042735042735042736,0.08547008547008547,0.042735042735042736,1.0,11.7,0.03908247497991088,inf,0.9553571428571429,3,0.042735042735042736
"frozenset({'native_country_aggregated_Other', 'workclass_Private'})",frozenset({'race_Asian-Pac-Islander'}),0.05982905982905983,0.06837606837606838,0.042735042735042736,0.7142857142857143,10.446428571428571,0.03864416684929506,3.260683760683761,0.9618181818181819,3,0.05982905982905983
"frozenset({'workclass_Private', 'race_Asian-Pac-Islander'})",frozenset({'native_country_aggregated_Other'}),0.042735042735042736,0.10256410256410256,0.042735042735042736,1.0,9.75,0.03835196142888451,inf,0.9375,3,0.042735042735042736
frozenset({'occupation_aggregated_Craft-repair'}),"frozenset({'race_White', 'age_education_interaction_(261.0, 369.0]'})",0.05982905982905983,0.07692307692307693,0.042735042735042736,0.7142857142857143,9.285714285714285,0.0381328073635766,3.2307692307692313,0.9490909090909091,3,0.05982905982905983
frozenset({'occupation_aggregated_Craft-repair'}),"frozenset({'age_education_interaction_(261.0, 369.0]', 'native_country_aggregated_United-States'})",0.05982905982905983,0.07692307692307693,0.042735042735042736,0.7142857142857143,9.285714285714285,0.0381328073635766,3.2307692307692313,0.9490909090909091,3,0.05982905982905983
"frozenset({'marital-status_Married-civ-spouse', 'race_Asian-Pac-Islander'})",frozenset({'native_country_aggregated_Other'}),0.05982905982905983,0.10256410256410256,0.05128205128205128,0.8571428571428571,8.357142857142858,0.04514573745342976,6.28205128205128,0.9363636363636363,3,0.05982905982905983
frozenset({'occupation_aggregated_Craft-repair'}),"frozenset({'age_education_interaction_(261.0, 369.0]'})",0.05982905982905983,0.08547008547008547,0.042735042735042736,0.7142857142857143,8.357142857142858,0.037621447877858136,3.200854700854701,0.9363636363636364,2,0.05982905982905983
"frozenset({'Cluster_(0.0, 2.0]', 'occupation_aggregated_Craft-repair'})","frozenset({'age_education_interaction_(261.0, 369.0]'})",0.05982905982905983,0.08547008547008547,0.042735042735042736,0.7142857142857143,8.357142857142858,0.037621447877858136,3.200854700854701,0.9363636363636364,3,0.05982905982905983
frozenset({'occupation_aggregated_Craft-repair'}),"frozenset({'Cluster_(0.0, 2.0]', 'age_education_interaction_(261.0, 369.0]'})",0.05982905982905983,0.08547008547008547,0.042735042735042736,0.7142857142857143,8.357142857142858,0.037621447877858136,3.200854700854701,0.9363636363636364,3,0.05982905982905983
"frozenset({'race_White', 'occupation_aggregated_Craft-repair'})","frozenset({'age_education_interaction_(261.0, 369.0]'})",0.05982905982905983,0.08547008547008547,0.042735042735042736,0.7142857142857143,8.357142857142858,0.037621447877858136,3.200854700854701,0.9363636363636364,3,0.05982905982905983
"frozenset({'native_country_aggregated_United-States', 'occupation_aggregated_Craft-repair'})","frozenset({'age_education_interaction_(261.0, 369.0]'})",0.05982905982905983,0.08547008547008547,0.042735042735042736,0.7142857142857143,8.357142857142858,0.037621447877858136,3.200854700854701,0.9363636363636364,3,0.05982905982905983
frozenset({'occupation_aggregated_Craft-repair'}),"frozenset({'education_HS-grad', 'sex_Male'})",0.05982905982905983,0.08547008547008547,0.042735042735042736,0.7142857142857143,8.357142857142858,0.037621447877858136,3.200854700854701,0.9363636363636364,3,0.05982905982905983
"frozenset({'race_Asian-Pac-Islander', 'sex_Male'})",frozenset({'native_country_aggregated_Other'}),0.05128205128205128,0.10256410256410256,0.042735042735042736,0.8333333333333334,8.125,0.037475345167652864,5.384615384615386,0.9243243243243244,3,0.05128205128205128
frozenset({'race_Asian-Pac-Islander'}),"frozenset({'marital-status_Married-civ-spouse', 'native_country_aggregated_Other'})",0.06837606837606838,0.09401709401709402,0.05128205128205128,0.7499999999999999,7.977272727272726,0.044853532033019214,3.623931623931622,0.9388379204892967,3,0.06837606837606838
"frozenset({'education-num_(10.0, 13.0]', 'age_(28.0, 37.0]'})","frozenset({'age_education_interaction_(369.0, 494.0]'})",0.05982905982905983,0.1282051282051282,0.05982905982905983,1.0,7.800000000000001,0.05215866754328293,inf,0.9272727272727274,3,0.05982905982905983
"frozenset({'education_Bachelors', 'age_(28.0, 37.0]'})","frozenset({'age_education_interaction_(369.0, 494.0]'})",0.05128205128205128,0.1282051282051282,0.05128205128205128,1.0,7.800000000000001,0.044707429322813935,inf,0.918918918918919,3,0.05128205128205128
frozenset({'race_Asian-Pac-Islander'}),frozenset({'native_country_aggregated_Other'}),0.06837606837606838,0.10256410256410256,0.05128205128205128,0.7499999999999999,7.312499999999999,0.04426912119219811,3.589743589743588,0.926605504587156,2,0.06837606837606838
"frozenset({'race_Asian-Pac-Islander', 'Cluster_(0.0, 2.0]'})",frozenset({'native_country_aggregated_Other'}),0.06837606837606838,0.10256410256410256,0.05128205128205128,0.7499999999999999,7.312499999999999,0.04426912119219811,3.589743589743588,0.926605504587156,3,0.06837606837606838
frozenset({'race_Asian-Pac-Islander'}),"frozenset({'native_country_aggregated_Other', 'Cluster_(0.0, 2.0]'})",0.06837606837606838,0.10256410256410256,0.05128205128205128,0.7499999999999999,7.312499999999999,0.04426912119219811,3.589743589743588,0.926605504587156,3,0.06837606837606838
frozenset({'occupation_aggregated_Craft-repair'}),"frozenset({'education_HS-grad', 'native_country_aggregated_United-States'})",0.05982905982905983,0.10256410256410256,0.042735042735042736,0.7142857142857143,6.964285714285714,0.03659872890642121,3.1410256410256414,0.9109090909090909,3,0.05982905982905983
"frozenset({'age_education_interaction_(494.0, 1350.0]', 'race_Asian-Pac-Islander'})",frozenset({'native_country_aggregated_Other'}),0.05982905982905983,0.10256410256410256,0.042735042735042736,0.7142857142857143,6.964285714285714,0.03659872890642121,3.1410256410256414,0.9109090909090909,3,0.05982905982905983
"frozenset({'sex_Male', 'occupation_aggregated_Craft-repair'})",frozenset({'education_HS-grad'}),0.05128205128205128,0.1282051282051282,0.042735042735042736,0.8333333333333334,6.500000000000001,0.03616042077580539,5.230769230769232,0.8918918918918919,3,0.05128205128205128
"frozenset({'education_HS-grad', 'age_education_interaction_(261.0, 369.0]'})","frozenset({'age_(28.0, 37.0]'})",0.042735042735042736,0.15384615384615385,0.042735042735042736,1.0,6.5,0.03616042077580539,inf,0.8839285714285714,3,0.042735042735042736
"frozenset({'age_education_interaction_(369.0, 494.0]', 'education-num_(10.0, 13.0]'})","frozenset({'age_(28.0, 37.0]'})",0.05982905982905983,0.15384615384615385,0.05982905982905983,1.0,6.5,0.05062458908612755,inf,0.9,3,0.05982905982905983
"frozenset({'education_Bachelors', 'age_education_interaction_(369.0, 494.0]'})","frozenset({'age_(28.0, 37.0]'})",0.05128205128205128,0.15384615384615385,0.05128205128205128,1.0,6.5,0.04339250493096647,inf,0.891891891891892,3,0.05128205128205128
frozenset({'occupation_aggregated_Craft-repair'}),"frozenset({'education_HS-grad', 'race_White'})",0.05982905982905983,0.1111111111111111,0.042735042735042736,0.7142857142857143,6.428571428571429,0.03608736942070276,3.111111111111111,0.8981818181818183,3,0.05982905982905983
"frozenset({'age_education_interaction_(261.0, 369.0]', 'sex_Male'})",frozenset({'education_HS-grad'}),0.05982905982905983,0.1282051282051282,0.042735042735042736,0.7142857142857143,5.571428571428572,0.035064650449265836,3.0512820512820515,0.8727272727272728,3,0.05982905982905983
"frozenset({'age_education_interaction_(261.0, 369.0]', 'age_(28.0, 37.0]'})",frozenset({'education_HS-grad'}),0.05982905982905983,0.1282051282051282,0.042735042735042736,0.7142857142857143,5.571428571428572,0.035064650449265836,3.0512820512820515,0.8727272727272728,3,0.05982905982905983
frozenset({'occupation_aggregated_Craft-repair'}),frozenset({'education_HS-grad'}),0.05982905982905983,0.1282051282051282,0.042735042735042736,0.7142857142857143,5.571428571428572,0.035064650449265836,3.0512820512820515,0.8727272727272728,2,0.05982905982905983
"frozenset({'Cluster_(0.0, 2.0]', 'occupation_aggregated_Craft-repair'})",frozenset({'education_HS-grad'}),0.05982905982905983,0.1282051282051282,0.042735042735042736,0.7142857142857143,5.571428571428572,0.035064650449265836,3.0512820512820515,0.8727272727272728,3,0.05982905982905983
frozenset({'occupation_aggregated_Craft-repair'}),"frozenset({'education_HS-grad', 'Cluster_(0.0, 2.0]'})",0.05982905982905983,0.1282051282051282,0.042735042735042736,0.7142857142857143,5.571428571428572,0.035064650449265836,3.0512820512820515,0.8727272727272728,3,0.05982905982905983
"frozenset({'race_White', 'occupation_aggregated_Craft-repair'})",frozenset({'education_HS-grad'}),0.05982905982905983,0.1282051282051282,0.042735042735042736,0.7142857142857143,5.571428571428572,0.035064650449265836,3.0512820512820515,0.8727272727272728,3,0.05982905982905983
"frozenset({'native_country_aggregated_United-States', 'occupation_aggregated_Craft-repair'})",frozenset({'education_HS-grad'}),0.05982905982905983,0.1282051282051282,0.042735042735042736,0.7142857142857143,5.571428571428572,0.035064650449265836,3.0512820512820515,0.8727272727272728,3,0.05982905982905983
"frozenset({'marital-status_Never-married', 'native_country_aggregated_United-States'})",frozenset({'relationship_Not-in-family'}),0.05982905982905983,0.13675213675213677,0.042735042735042736,0.7142857142857143,5.223214285714286,0.034553290963547374,3.0213675213675217,0.86,3,0.05982905982905983
"frozenset({'marital-status_Married-civ-spouse', 'age_education_interaction_(261.0, 369.0]'})","frozenset({'age_(28.0, 37.0]'})",0.05982905982905983,0.15384615384615385,0.042735042735042736,0.7142857142857143,4.642857142857142,0.03353057199211045,2.9615384615384617,0.8345454545454545,3,0.05982905982905983
"frozenset({'age_education_interaction_(261.0, 369.0]', 'sex_Male'})","frozenset({'age_(28.0, 37.0]'})",0.05982905982905983,0.15384615384615385,0.042735042735042736,0.7142857142857143,4.642857142857142,0.03353057199211045,2.9615384615384617,0.8345454545454545,3,0.05982905982905983
"frozenset({'age_education_interaction_(261.0, 369.0]'})","frozenset({'age_(28.0, 37.0]'})",0.08547008547008547,0.15384615384615385,0.05982905982905983,0.7000000000000001,4.55,0.04667981591058514,2.820512820512821,0.8531375166889185,2,0.08547008547008547
"frozenset({'Cluster_(0.0, 2.0]', 'age_education_interaction_(261.0, 369.0]'})","frozenset({'age_(28.0, 37.0]'})",0.08547008547008547,0.15384615384615385,0.05982905982905983,0.7000000000000001,4.55,0.04667981591058514,2.820512820512821,0.8531375166889185,3,0.08547008547008547
"frozenset({'age_education_interaction_(261.0, 369.0]'})","frozenset({'Cluster_(0.0, 2.0]', 'age_(28.0, 37.0]'})",0.08547008547008547,0.15384615384615385,0.05982905982905983,0.7000000000000001,4.55,0.04667981591058514,2.820512820512821,0.8531375166889185,3,0.08547008547008547
"frozenset({'age_education_interaction_(494.0, 1350.0]', 'education-num_(10.0, 13.0]'})",frozenset({'education_Bachelors'}),0.19658119658119658,0.24786324786324787,0.19658119658119658,1.0,4.0344827586206895,0.1478559427277376,inf,0.9361702127659576,3,0.19658119658119658
"frozenset({'education-num_(10.0, 13.0]', 'occupation_aggregated_Exec-managerial'})",frozenset({'education_Bachelors'}),0.11965811965811966,0.24786324786324787,0.11965811965811966,1.0,4.0344827586206895,0.08999926948644899,inf,0.8543689320388351,3,0.11965811965811966
"frozenset({'education-num_(10.0, 13.0]', 'age_(47.0, 90.0]'})",frozenset({'education_Bachelors'}),0.08547008547008547,0.24786324786324787,0.08547008547008547,1.0,4.0344827586206895,0.06428519249032069,inf,0.822429906542056,3,0.08547008547008547
"frozenset({'workclass_Self-emp-inc', 'education-num_(10.0, 13.0]'})",frozenset({'education_Bachelors'}),0.06837606837606838,0.24786324786324787,0.06837606837606838,1.0,4.0344827586206895,0.05142815399225656,inf,0.8073394495412843,3,0.06837606837606838
"frozenset({'age_(37.0, 47.0]', 'education-num_(10.0, 13.0]'})",frozenset({'education_Bachelors'}),0.1111111111111111,0.24786324786324787,0.1111111111111111,1.0,4.0344827586206895,0.08357075023741689,inf,0.846153846153846,3,0.1111111111111111
"frozenset({'relationship_Not-in-family', 'education-num_(10.0, 13.0]'})",frozenset({'education_Bachelors'}),0.042735042735042736,0.24786324786324787,0.042735042735042736,1.0,4.0344827586206895,0.032142596245160346,inf,0.7857142857142856,3,0.042735042735042736
"frozenset({'education-num_(10.0, 13.0]', 'occupation_aggregated_Sales'})",frozenset({'education_Bachelors'}),0.06837606837606838,0.24786324786324787,0.06837606837606838,1.0,4.0344827586206895,0.05142815399225656,inf,0.8073394495412843,3,0.06837606837606838
frozenset({'education_Bachelors'}),"frozenset({'age_education_interaction_(494.0, 1350.0]', 'education-num_(10.0, 13.0]'})",0.24786324786324787,0.19658119658119658,0.19658119658119658,0.793103448275862,4.0344827586206895,0.1478559427277376,3.8831908831908817,1.0000000000000002,3,0.24786324786324787
